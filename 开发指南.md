# FastAPI 项目开发指南

## 📚 目录
1. [Flask vs FastAPI 核心区别（通俗版）](#1-flask-vs-fastapi-核心区别)
2. [流式响应设计说明](#2-流式响应设计说明)
3. [模块化设计最佳实践](#3-模块化设计最佳实践)
4. [软件设计方法论](#4-软件设计方法论)
5. [如何给AI提需求（提示词模板）](#5-如何给ai提需求)

---

## 1. Flask vs FastAPI 核心区别

### 🍔 用餐厅比喻理解同步vs异步

#### **Flask = 传统餐厅（同步）**

```
场景：10个座位，10个服务员

客人A点餐：牛排（需要厨房30分钟）
服务员1：站在厨房门口等30分钟 ❌（啥也不干）

客人B点餐：沙拉（需要10分钟）
服务员2：站在厨房门口等10分钟 ❌

...

第11个客人来了：
→ 没有服务员了，必须等前面的客人吃完！⏳
```

**问题：**
- 服务员等待时很浪费（站着发呆）
- 同时只能服务10个客人
- 第11个客人要等很久

---

#### **FastAPI = 智能餐厅（异步）**

```
场景：10个座位，只需要2个服务员！

客人A点餐：牛排（需要30分钟）
服务员1：下单后立即去服务其他客人 ✅

客人B点餐：沙拉（需要10分钟）
服务员1：下单后立即去服务其他客人 ✅

客人C、D、E... 100个人同时来：
服务员1和2：不停地接单、传菜
（厨房通知：A的牛排好了！→ 立即送给A）
（厨房通知：B的沙拉好了！→ 立即送给B）

所有客人都得到了服务！✅
```

**优势：**
- 服务员不浪费时间（一直在干活）
- 2个服务员可以服务100个客人
- 每个客人等待时间只跟厨房速度有关

---

### 💡 核心原理

| 特性 | Flask（同步） | FastAPI（异步） |
|------|--------------|----------------|
| **等待外部API** | 线程被锁死，啥也不干 | 线程去处理其他请求 |
| **并发能力** | 线程数量 = 最大并发 | 1个线程 = 处理几千个请求 |
| **资源占用** | 高（每个请求占1个线程） | 低（事件循环） |
| **适用场景** | 计算密集型 | I/O密集型（数据库、API调用） |

---

### 🎯 您的项目为什么适合FastAPI？

您的项目有这些特点：
1. **AI聊天**：调用外部API，需要等待1-60秒
2. **数据库查询**：SQLite读取，需要等待几毫秒
3. **Excel加载**：后台任务，需要1-2分钟
4. **在线统计**：高频率轻量请求

这些都是 **I/O密集型操作**（等待时间多，计算时间少）

**结论：FastAPI比Flask快3-5倍，资源占用少90%！**

---

## 2. 流式响应设计说明

### ✨ 新功能：像ChatGPT那样逐字显示

#### **之前的设计（普通响应）：**

```
用户发送消息
  ↓
显示"思考中..."
  ↓
等待60秒（AI处理）⏳
  ↓
一次性显示完整回复
```

**问题：** 用户等待60秒，体验差

---

#### **现在的设计（流式响应）：**

```
用户发送消息
  ↓
显示空气泡
  ↓
AI返回第1个字："你" → 立即显示
AI返回第2个字："好" → 立即显示
AI返回第3个字："，" → 立即显示
...
AI返回完毕 → 流结束
```

**优势：**
- ✅ 用户立即看到反馈（不再焦虑）
- ✅ 体验更流畅（像人在打字）
- ✅ 可以提前停止生成（未来可扩展）

---

#### **技术实现：**

**后端（FastAPI）：**
```python
@router.post("/api/ai/chat/stream")
async def api_ai_chat_stream():
    async def generate_stream():
        # 请求硅基流动API，开启stream=True
        async with client.stream("POST", url) as response:
            async for line in response.aiter_lines():
                # 每收到一个字符块，立即返回给前端
                yield f"data: {content_chunk}\n\n"
    
    return StreamingResponse(generate_stream())
```

**前端（JavaScript）：**
```javascript
// 使用ReadableStream接收流式数据
const reader = response.body.getReader();
while (true) {
    const {done, value} = await reader.read();
    // 每收到一个字符块，立即更新界面
    pendingBubble.textContent += chunk;
}
```

---

#### **对比Flask：**

| 特性 | Flask | FastAPI |
|------|-------|---------|
| **流式响应** | 困难（需要复杂workaround） | 原生支持 |
| **代码复杂度** | 高 | 低 |
| **性能** | 一般 | 优秀 |

**Flask实现流式响应需要：**
```python
# Flask需要用yield + stream_with_context
@app.route("/stream")
def stream():
    def generate():
        # 无法使用异步，性能差
        for chunk in sync_api_call():
            yield chunk
    return Response(stream_with_context(generate()))
```

**FastAPI只需要：**
```python
@router.post("/stream")
async def stream():
    async def generate():
        # 原生异步，性能好
        async for chunk in async_api_call():
            yield chunk
    return StreamingResponse(generate())
```

---

## 3. 模块化设计最佳实践

### 🏗️ 为什么要把代码分离？

#### **Flask版本（单文件地狱）：**

```
flask版本-存档/
└── app.py  (1036行！！！)
    ├── 配置
    ├── 数据库操作
    ├── Excel加载
    ├── 今日一签
    ├── AI聊天
    ├── 在线统计
    ├── 单词查询
    └── ... 所有功能混在一起
```

**问题：**
- ❌ 难以查找代码（1036行要翻很久）
- ❌ 多人协作冲突（都改同一个文件）
- ❌ 难以测试（功能耦合）
- ❌ 难以复用（代码混在一起）

---

#### **FastAPI版本（模块化）：**

```
fastapi版本/
├── main.py               (100行，只负责启动)
├── core/                 (核心功能)
│   ├── config.py         (配置管理，50行)
│   ├── database.py       (数据库，80行)
│   ├── loading.py        (加载状态，60行)
│   └── utils.py          (工具函数，40行)
└── routers/              (按功能分离)
    ├── site.py           (在线统计，40行)
    ├── todayphrase.py    (今日一签，60行)
    ├── sentences.py      (情境句，50行)
    ├── excel.py          (Excel管理，100行)
    ├── lookup.py         (单词查询，40行)
    ├── wordbook.py       (单词库，70行)
    └── ai.py             (AI聊天，200行，新增流式响应)
```

**优势：**
- ✅ 清晰明了（每个文件只做一件事）
- ✅ 易于维护（改AI聊天只需要看ai.py）
- ✅ 易于测试（单独测试每个模块）
- ✅ 易于复用（其他项目可以直接复用routers/ai.py）
- ✅ 多人协作（不同人改不同文件，不冲突）

---

### 📐 模块化设计原则

#### **1. 单一职责原则（SRP）**

每个文件只负责一个功能：

```python
# ❌ 不好：一个文件做太多事
# app.py
def load_excel(): ...
def chat_ai(): ...
def search_word(): ...
def get_online_count(): ...

# ✅ 好：每个文件专注一件事
# routers/excel.py
def load_excel(): ...

# routers/ai.py
def chat_ai(): ...
def chat_stream(): ...

# routers/lookup.py
def search_word(): ...
```

---

#### **2. 分层架构**

```
请求 → 路由层 → 业务逻辑层 → 数据层
```

**示例：**

```python
# routers/lookup.py（路由层）
@router.get("/api/lookup")
async def api_lookup(word: str):
    # 1. 参数验证
    if not word:
        raise HTTPException(400)
    
    # 2. 调用业务逻辑
    result = database.search_word(word)
    
    # 3. 返回结果
    return result

# core/database.py（数据层）
def search_word(word: str):
    # 只负责数据库操作
    return db.query(word)
```

**好处：**
- 路由层可以换成GraphQL，数据层不需要改
- 数据层可以从SQLite换成PostgreSQL，路由层不需要改

---

#### **3. 配置集中管理**

```python
# ❌ 不好：配置散落各处
# ai.py
API_URL = "https://..."

# excel.py
DATA_DIR = "/path/to/data"

# ✅ 好：配置统一管理
# core/config.py
API_URL = "https://..."
DATA_DIR = Path(__file__).parent.parent / "data"
SQLITE_DB_PATH = Path(__file__).parent.parent / "sqlite" / "paraphrase.sqlite"

# 其他文件导入
from core.config import API_URL, DATA_DIR
```

**好处：**
- 修改配置只需要改一个文件
- 容易切换开发/生产环境

---

## 4. 软件设计方法论

### 🎨 从需求到代码的思考流程

#### **步骤1：明确需求**

**问自己：**
1. 这个功能要解决什么问题？
2. 谁会使用这个功能？
3. 使用频率如何？（高频/低频）
4. 性能要求如何？（实时/可以等待）

**示例：AI聊天**
- 问题：用户想快速翻译/解释内容
- 用户：所有访客
- 频率：中等（每人每天5-10次）
- 性能：可以等待，但要有反馈（流式响应）

---

#### **步骤2：拆解功能**

**画出数据流：**

```
用户输入
  ↓
前端JS（验证、禁用输入）
  ↓
发送POST请求 /api/ai/chat/stream
  ↓
后端FastAPI
  ├── 验证参数（API key、内容）
  ├── 调用外部API（硅基流动）
  └── 流式返回结果
  ↓
前端接收流
  ├── 逐字更新界面
  └── 完成后重新启用输入
```

---

#### **步骤3：确定技术选型**

**决策表：**

| 需求 | 选项A | 选项B | 选择 | 原因 |
|------|-------|-------|------|------|
| 后端框架 | Flask | FastAPI | **FastAPI** | 异步I/O，流式响应简单 |
| 前端框架 | React | 原生JS | **原生JS** | 页面简单，无需框架 |
| 数据库 | MySQL | SQLite | **SQLite** | 单机部署，数据量小 |
| 流式传输 | WebSocket | SSE | **SSE** | 单向传输，实现简单 |

---

#### **步骤4：模块划分**

**按功能垂直切分：**

```
AI聊天功能 → routers/ai.py
  ├── 普通聊天接口
  ├── 流式聊天接口
  └── API密钥管理

前端JS → static/js/ai_chat.js
  ├── 发送消息
  ├── 接收流式响应
  └── UI更新
```

---

#### **步骤5：编码规范**

```python
# 好的代码应该：
# 1. 有清晰的函数命名
async def api_ai_chat_stream():  # ✅ 一看就懂

# 2. 有类型提示
async def search_word(word: str) -> Dict[str, Any]:  # ✅

# 3. 有注释说明
async def generate_stream() -> AsyncGenerator[str, None]:
    """生成流式响应，逐字返回AI回复"""  # ✅

# 4. 有错误处理
try:
    result = await api_call()
except HTTPError as e:
    raise HTTPException(502, detail=str(e))  # ✅
```

---

## 5. 如何给AI提需求

### 📝 提示词模板

#### **模板1：新增功能**

```
【背景】
我有一个FastAPI项目，是词汇学习系统。
当前已有功能：单词查询、AI聊天、Excel加载。

【需求】
我想新增一个"每日一词"功能：
1. 每天0点自动从词库随机选一个单词
2. 在首页展示单词、音标、释义
3. 用户可以点击"换一个"按钮

【技术要求】
- 后端：FastAPI，数据存在SQLite
- 前端：原生JS，不使用框架
- 存储：将每日单词ID存在JSON文件

【期望输出】
1. 后端路由代码（routers/daily_word.py）
2. 前端JS代码（static/js/daily_word.js）
3. 定时任务代码
4. 说明如何集成到现有项目
```

---

#### **模板2：优化现有功能**

```
【当前实现】
我的AI聊天功能会阻塞60秒，多用户同时使用会排队。
[粘贴当前代码]

【问题】
1. 10个用户同时使用，后面的要等待
2. 体验差，没有实时反馈

【期望优化】
1. 改为异步处理，支持高并发
2. 添加流式响应，像ChatGPT那样逐字显示
3. 保持向后兼容（旧接口继续工作）

【技术栈】
- 后端：FastAPI + httpx
- 前端：原生JS，使用fetch API

【期望输出】
1. 改进后的后端代码
2. 改进后的前端代码
3. 新旧对比说明
4. 性能提升预估
```

---

#### **模板3：重构代码**

```
【当前情况】
我的Flask项目所有代码在app.py（1000+行），难以维护。
[粘贴部分代码]

【重构目标】
1. 拆分成模块化结构
2. 迁移到FastAPI
3. 保持所有功能不变

【项目结构】
- AI聊天
- 单词查询
- Excel管理
- 在线统计

【期望输出】
1. 新的项目结构设计
2. 每个模块的代码
3. 迁移步骤说明
4. 新旧架构对比
```

---

#### **模板4：问题诊断**

```
【问题描述】
AI聊天功能偶尔会返回空回复。

【相关代码】
[粘贴代码]

【错误日志】
[粘贴日志]

【已尝试】
1. 检查API key，正常
2. 手动调用外部API，返回正常

【期望】
1. 分析可能的原因
2. 提供修复方案
3. 添加更好的错误处理
```

---

### 💡 提示词技巧

#### **1. 提供上下文**

```
❌ 不好："帮我写个AI聊天功能"
✅ 好："我有个FastAPI项目，需要添加AI聊天，调用硅基流动API，支持流式响应"
```

---

#### **2. 说明约束条件**

```
❌ 不好："优化性能"
✅ 好："服务器2核2GB，目前10个并发就卡，希望支持100个并发"
```

---

#### **3. 给出示例**

```
❌ 不好："我想要流式响应"
✅ 好："我想要像ChatGPT那样的流式响应，回复一个字显示一个字，参考这个效果：[截图]"
```

---

#### **4. 明确技术栈**

```
❌ 不好："用Python实现"
✅ 好："用FastAPI + httpx实现，不要用requests（因为不支持async）"
```

---

### 🎯 与AI协作的最佳实践

#### **1. 迭代式开发**

```
第1轮：实现基本功能（普通AI聊天）
第2轮：添加流式响应
第3轮：添加模型选择
第4轮：添加历史记录
```

不要一次性要求所有功能！

---

#### **2. 代码审查**

收到AI代码后，检查：
- ✅ 是否有错误处理？
- ✅ 是否有类型提示？
- ✅ 是否有注释说明？
- ✅ 是否符合项目现有风格？

---

#### **3. 测试验证**

```
1. 正常情况：输入正确，返回正常
2. 边界情况：输入为空，返回错误提示
3. 异常情况：API超时，返回友好错误
4. 并发情况：多用户同时使用，不冲突
```

---

## 📌 总结

### FastAPI vs Flask 一句话总结

**Flask = 传统同步，适合简单项目**  
**FastAPI = 现代异步，适合高并发I/O密集型项目**

### 模块化设计一句话总结

**不要把所有代码写在一个文件！按功能拆分，每个文件只做一件事。**

### 给AI提需求一句话总结

**说清楚背景、需求、约束、期望，提供示例和代码，一步步迭代。**

---

## 🚀 下一步行动

1. ✅ **已完成**：流式响应功能
2. **建议添加**：
   - 聊天历史记录（存在浏览器localStorage）
   - 单词收藏功能（收藏到本地）
   - 学习进度跟踪（已学多少单词）
   - 导出学习笔记（Markdown格式）

3. **性能优化**：
   - 添加缓存（Redis或内存缓存）
   - 图片懒加载
   - 数据库查询优化

4. **部署建议**：
   - 使用Nginx反向代理
   - 配置SSL证书（Let's Encrypt）
   - 使用systemd管理进程
   - 配置日志轮转

---

**祝您开发顺利！🎉**

